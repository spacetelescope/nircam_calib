{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAR-19 Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the code in the nircam_calib/comissioning/NRC_19_subarrays module in order to analyze data from CAR-19 (Subarray Verification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Goal 1: Register and combine data in pipeline](#goal_1)\n",
    "* [Goal 2: Confirm positions of subarrays on detectors](#goal_2)\n",
    "    * [Manual examination of images](#manual_examination)\n",
    "    * [Compare source locations](#source_locations)\n",
    "* [Goal 3: Confirm telescope pointing places target in correct location](#goal_3)\n",
    "    * [Compare source locations to 2MASS catalog](#twomass_comp)\n",
    "    * [Compare target location to expected location](#targ_star_comp)\n",
    "    * [Check that target RA, Dec in file matches position in APT](#targ_ra_dec_comp)\n",
    "* [Goal 4: Confirm same charge accumulation rate in subarrays vs full frame](#goal_4)\n",
    "    * [Compare photometry in subarrays vs full frame](#photometry_comparison)\n",
    "    * [Compare level 3 source catalogs](#compare_level3_catalog)\n",
    "    * [Examine ratio images with the same pointing](#ratios)\n",
    "* [Goal 5: Identify and characterize latency effects](#goal_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jwst.associations.asn_from_list import asn_from_list\n",
    "from jwst.associations.lib.rules_level2_base import DMSLevel2bBase\n",
    "from jwst.associations.lib.rules_level2b import Asn_Lv2ImageTSO, Asn_Lv2SpecTSO\n",
    "from jwst.associations.lib.rules_level3 import Asn_TSO\n",
    "from jwst.pipeline.calwebb_detector1 import Detector1Pipeline\n",
    "from jwst.pipeline.calwebb_image2 import Image2Pipeline\n",
    "from jwst.pipeline.calwebb_spec2 import Spec2Pipeline\n",
    "from jwst.pipeline.calwebb_image3 import Image3Pipeline\n",
    "from jwst.pipeline.calwebb_tso3 import Tso3Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nircam_calib.commissioning.NRC_19_subarrays import confirm_subarray_location_via_sources as locations\n",
    "from nircam_calib.commissioning.NRC_19_subarrays import confirm_subarray_location_via_examination as examination\n",
    "from nircam_calib.commissioning.NRC_19_subarrays import confirm_telescope_pointing as pointing\n",
    "from nircam_calib.commissioning.NRC_19_subarrays import confirm_count_rates as count_rates\n",
    "from nircam_calib.commissioning.NRC_19_subarrays import latency_investigation as latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CRDS_SERVER_URL\"] = \"https://jwst-crds.stsci.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/ifs/jwst/wit/nircam/simulationWG/Imaging/CAR-19/2020_Oct'\n",
    "#base_dir = 'path_to_simulationWG_CAR-19_directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir_exists(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_products_dir = os.path.join(base_dir, 'Analysis_products')\n",
    "ensure_dir_exists(output_products_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwst\n",
    "print(jwst.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RA and Dec of the target, as defined in the APT file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In goal #2, these will be compared to the TARG_RA, TARG_DEC keyword values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_target_ra, extended_target_dec = '05 21 57.0000', '-69 29 51.00'\n",
    "ptsrc_target_ra, ptsrc_target_dec = '05 21 55.8098', '-69 29 38.25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ra_dec_dec_degrees(str_value, ra_hours=False):\n",
    "    \"\"\"Convert string representation of RA or Dec to decimal degrees\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    str_value : str\n",
    "        String value of RA or Dec separated by spaces (e.g. '05 21 55.8098')\n",
    "        since this is the way it is presented in APT\n",
    "        \n",
    "    ra_hours : bool\n",
    "        If True, the input is assumed to be RA in units of hours/minutes/seconds.\n",
    "        If False, the input is assumed to be degrees/arcmin/arcsec\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    deg_value : float\n",
    "        ```str_value``` converted to decimal degrees\n",
    "    \"\"\"\n",
    "    d, m, s = str_value.split(' ')\n",
    "    d_dec = np.float(d)\n",
    "    m_dec = np.float(m)\n",
    "    s_dec = np.float(s)\n",
    "    if d_dec < 0:\n",
    "        m_dec = 0. - m_dec\n",
    "        s_dec = 0. - s_dec\n",
    "    deg_value = d_dec + (m_dec + (s_dec / 60.)) / 60.\n",
    "    if ra_hours:\n",
    "        deg_value *= 15.\n",
    "    return deg_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_ra = ra_dec_dec_degrees(extended_target_ra, ra_hours=True)\n",
    "extended_dec = ra_dec_dec_degrees(extended_target_dec)\n",
    "point_ra = ra_dec_dec_degrees(ptsrc_target_ra, ra_hours=True)\n",
    "point_dec = ra_dec_dec_degrees(ptsrc_target_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extended_ra, extended_dec)\n",
    "print(point_ra, point_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='goal_1'></a>\n",
    "## Goal 1: Check that calibration pipeline correctly registers and combines subarray data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Run pipeline through level3 separately for each aperture\n",
    " \n",
    " examine output:  \n",
    "      measure FWHM of sources  \n",
    "      visual inspection of mosaic size/shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calwebb_detector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1_output_dir = os.path.join(base_dir, 'Pipeline_level1/')\n",
    "ensure_dir_exists(pipeline1_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_calwebb_detector1(filename, ta=False):\n",
    "    m = Detector1Pipeline() #config_file=os.path.join(base_dir, 'pipeline_config_files/calwebb_detector1.cfg'))\n",
    "\n",
    "    # make changes to the parameters/reference files used\n",
    "    m.refpix.odd_even_rows = False\n",
    "\n",
    "    # jump step is way too sensitive\n",
    "    m.jump.rejection_threshold = 91\n",
    "\n",
    "    # skip steps you don't want to run\n",
    "    m.group_scale.skip = True\n",
    "    m.ipc.skip = True\n",
    "    m.persistence.skip = True\n",
    "    \n",
    "    # skip dark subtraction on TA files\n",
    "    if ta:\n",
    "        m.dark_current.skip = True\n",
    "\n",
    "    # name your output file\n",
    "    m.save_results = True\n",
    "    m.output_dir = pipeline1_output_dir\n",
    "    m.output_file = os.path.basename(filename.replace('_uncal', '_rate'))\n",
    "\n",
    "    # run the pipeline with these paramters\n",
    "    m.run(filename)\n",
    "    print('')\n",
    "    print(\"Done running CALDETECTOR1 on {}\".format(filename))\n",
    "    print(\"Output saved to {}\".format(os.path.join(m.output_dir, m.output_file)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run calwebb_detector1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TA images can be used in a few of the tests below, so let's run them as well. We will have to explicitly skip dark current subtraction for them since there are no dark reference files in CRDS for those apertures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncal_files = sorted(glob(os.path.join(base_dir, 'Mirage_Output/j*uncal.fits')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_uncal_files = ['Mirage_Output/jw01068005001_01101_00001_nrcb5_uncal.fits',\n",
    "                  'Mirage_Output/jw01068006001_01101_00001_nrcb5_uncal.fits',\n",
    "                  'Mirage_Output/jw01068007001_01101_00001_nrca5_uncal.fits']\n",
    "ta_uncal_files = [os.path.join(base_dir, f) for f in ta_uncal_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process TA files separately\n",
    "for f in ta_uncal_files:\n",
    "    uncal_files.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run non-TA files through calwebb_detector1\n",
    "for filename in uncal_files:\n",
    "    #for filename in [os.path.join(base_dir, 'Mirage_Output/jw01068007001_01101_00001-seg001_nrca3_uncal.fits')]:\n",
    "    run_calwebb_detector1(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TA files through calwebb_detector1.\n",
    "# This is done separately from the other files so that we can skip dark subtraction\n",
    "for filename in ta_uncal_files:\n",
    "    run_calwebb_detector1(filename, ta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calwebb_image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2_output_dir = os.path.join(base_dir, 'Pipeline_level2/')\n",
    "ensure_dir_exists(pipeline2_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_level2_association(file_list, asn_filename, rule=None):\n",
    "    idx = file_list[0].find('nrca1')\n",
    "    prod_name = file_list[0][0: idx+5]\n",
    "    if rule is None:\n",
    "        asn = asn_from_list(file_list, rule=DMSLevel2bBase, product_name=prod_name)\n",
    "    elif rule.lower() == 'asn_lv2imagetso':\n",
    "        asn = asn_from_list(file_list, product_name=prod_name, rule=Asn_Lv2ImageTSO)\n",
    "    elif rule.lower() == 'asn_lv2spectso':\n",
    "        asn = asn_from_list(file_list, product_name=prod_name, rule=Asn_Lv2SpecTSO)\n",
    "    outfile = os.path.join(pipeline2_output_dir, asn_filename)\n",
    "    with open(outfile, 'w') as fh:\n",
    "        fh.write(asn.dump()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_calwebb_image2(filename):\n",
    "    result2 = Image2Pipeline()\n",
    "    result2.save_results = True\n",
    "    result2.output_dir = pipeline2_output_dir\n",
    "    result2.run(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_calwebb_spec2(filename):\n",
    "    result2 = Spec2Pipeline()\n",
    "    result2.save_results = True\n",
    "    result2.output_dir = pipeline2_output_dir\n",
    "    result2.run(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create association files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create association files. For level2 it's not as important, but let's make one association file for each subarray size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub160_asn = os.path.join(pipeline2_output_dir, 'level2_sub160_files_asn.json')\n",
    "sub160_rate_files = sorted(glob(os.path.join(pipeline1_output_dir, 'jw01068001001*rate.fits')))\n",
    "make_level2_association(sub160_rate_files, sub160_asn)\n",
    "\n",
    "sub320_asn = os.path.join(pipeline2_output_dir, 'level2_sub320_files_asn.json')\n",
    "sub320_rate_files = sorted(glob(os.path.join(pipeline1_output_dir, 'jw01068002001*rate.fits')))\n",
    "make_level2_association(sub320_rate_files, sub320_asn)\n",
    "\n",
    "sub640_asn = os.path.join(pipeline2_output_dir, 'level2_sub640_files_asn.json')\n",
    "sub640_rate_files = sorted(glob(os.path.join(pipeline1_output_dir, 'jw01068003001*rate.fits')))\n",
    "make_level2_association(sub640_rate_files, sub640_asn)\n",
    "\n",
    "full_asn = os.path.join(pipeline2_output_dir, 'level2_full_files_asn.json')\n",
    "full_rate_files = sorted(glob(os.path.join(pipeline1_output_dir, 'jw01068004001*rate.fits')))\n",
    "make_level2_association(full_rate_files, full_asn)\n",
    "\n",
    "sub400p_asn = os.path.join(pipeline2_output_dir, 'level2_sub400p_files_asn.json')\n",
    "sub400p_rate_files = sorted(glob(os.path.join(pipeline1_output_dir, 'jw01068005001*rateints.fits')))\n",
    "make_level2_association(sub400p_rate_files, sub400p_asn, rule='Asn_Lv2ImageTSO')\n",
    "\n",
    "sub64p_asn = os.path.join(pipeline2_output_dir, 'level2_sub64p_files_asn.json')\n",
    "sub64p_rate_files = sorted(glob(os.path.join(pipeline1_output_dir, 'jw01068006001*rateints.fits')))\n",
    "make_level2_association(sub64p_rate_files, sub64p_asn, rule='Asn_Lv2ImageTSO')\n",
    "\n",
    "substripe256_asn = os.path.join(pipeline2_output_dir, 'level2_substrip256_files_asn.json')\n",
    "substripe256_rate_files = sorted(glob(os.path.join(pipeline1_output_dir,\n",
    "                                                   'jw01068007001*nrca[1234]*rateints.fits')))\n",
    "make_level2_association(substripe256_rate_files, substripe256_asn, rule='Asn_Lv2ImageTSO')\n",
    "\n",
    "substripe256_grism_asn = os.path.join(pipeline2_output_dir, 'level2_substrip256_grism_files_asn.json')\n",
    "substripe256_grism_rate_files = sorted(glob(os.path.join(pipeline1_output_dir,\n",
    "                                                         'jw01068007001*00002*nrca5*rateints.fits')))\n",
    "make_level2_association(substripe256_grism_rate_files, substripe256_grism_asn, rule='Asn_Lv2SpecTSO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Run calwebb_image2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on imaging mode files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "association_files = [sub160_asn, sub320_asn, sub640_asn, full_asn, sub400p_asn, sub64p_asn, substripe256_asn]\n",
    "for asn in association_files:\n",
    "    run_calwebb_image2(asn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run calwebb_spec2 on the grism TSO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calwebb_spec2(substripe256_grism_asn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calwebb_image3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline3_output_dir = os.path.join(base_dir, 'Pipeline_level3/')\n",
    "ensure_dir_exists(pipeline3_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_calwebb_image3(filename):\n",
    "    result = Image3Pipeline()\n",
    "    result.save_results = True\n",
    "    result.source_catalog.save_results = True\n",
    "    result.source_catalog.output_dir = pipeline3_output_dir\n",
    "    result.output_dir = pipeline3_output_dir\n",
    "    result.run(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_calwebb_tso3(filename):\n",
    "    result = Tso3Pipeline()\n",
    "    result.save_results = True\n",
    "    result.tso_photometry.save_catalog = True\n",
    "    result.tso_photometry.output_dir = pipeline3_output_dir\n",
    "    result.output_dir = pipeline3_output_dir\n",
    "    result.run(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create association files for various combinations of images. Let's try:\n",
    "\n",
    "1. Combining all data (FULL, SUB640, SUB320, SUB160, SUB400P, SUB64P)\n",
    "2. Combine each subarray separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create association files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_level3_association(file_list, asn_filename, product_name, rule=None):\n",
    "    if rule is None:\n",
    "        asn = asn_from_list(file_list, product_name=product_name)\n",
    "    elif rule.lower() == 'asn_tso':\n",
    "        asn = asn_from_list(file_list, product_name=product_name, rule=Asn_TSO)\n",
    "    outfile = os.path.join(pipeline3_output_dir, asn_filename)\n",
    "    with open(outfile, 'w') as fh:\n",
    "        fh.write(asn.dump()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output names and get file lists\n",
    "sub160_sw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_sub160_sw_files_asn.json')\n",
    "sub160_sw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068001001*nrcb[1234]_cal.fits')))\n",
    "\n",
    "sub160_lw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_sub160_lw_files_asn.json')\n",
    "sub160_lw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068001001*nrcb5_cal.fits')))\n",
    "\n",
    "sub320_sw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_sub320_sw_files_asn.json')\n",
    "sub320_sw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068002001*nrcb[1234]_cal.fits')))\n",
    "\n",
    "sub320_lw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_sub320_lw_files_asn.json')\n",
    "sub320_lw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068002001*nrcb5_cal.fits')))\n",
    "\n",
    "sub640_sw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_sub640_sw_files_asn.json')\n",
    "sub640_sw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068003001*nrcb[1234]_cal.fits')))\n",
    "\n",
    "sub640_lw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_sub640_lw_files_asn.json')\n",
    "sub640_lw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068003001*nrcb5_cal.fits')))\n",
    "\n",
    "full_sw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_full_sw_files_asn.json')\n",
    "full_sw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068004001*nrcb[1234]_cal.fits')))\n",
    "\n",
    "full_lw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_full_lw_files_asn.json')\n",
    "full_lw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068004001*nrcb5_cal.fits')))\n",
    "\n",
    "sub400p_sw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_sub400p_sw_files_asn.json')\n",
    "sub400p_sw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068005001*nrcb[1234]_calints.fits')))\n",
    "\n",
    "sub400p_lw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_sub400p_lw_files_asn.json')\n",
    "sub400p_lw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068005001*00002_nrcb5_calints.fits')))\n",
    "\n",
    "# Omit the TA image\n",
    "sub64p_sw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_sub64p_sw_files_asn.json')\n",
    "sub64p_sw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068006001*nrcb[1234]_calints.fits')))\n",
    "\n",
    "# Omit the TA image\n",
    "sub64p_lw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_sub64p_lw_files_asn.json')\n",
    "sub64p_lw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068006001*00002_nrcb5_calints.fits')))\n",
    "\n",
    "substripe256_sw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_substripe256_sw_files_asn.json')\n",
    "substripe256_sw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068007001*nrc?[1234]_calints.fits')))\n",
    "\n",
    "substripe256_lw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_substripe256_lw_files_asn.json')\n",
    "substripe256_lw_cal_files = sorted(glob(os.path.join(pipeline2_output_dir, 'jw01068007001*00002*nrca5_calints.fits')))\n",
    "\n",
    "all_sw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_all_sw_subarrays_asn.json')\n",
    "all_sw_cal_files = sub160_sw_cal_files + sub320_sw_cal_files + sub640_sw_cal_files + full_sw_cal_files\n",
    "\n",
    "all_lw_asn_3 = os.path.join(pipeline3_output_dir, 'level3_all_lw_subarrays_asn.json')\n",
    "all_lw_cal_files = sub160_lw_cal_files + sub320_lw_cal_files + sub640_lw_cal_files + full_lw_cal_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Image3 association files\n",
    "make_level3_association(sub160_sw_cal_files, sub160_sw_asn_3, 'sub160_sw')\n",
    "make_level3_association(sub160_lw_cal_files, sub160_lw_asn_3, 'sub160_lw')\n",
    "\n",
    "make_level3_association(sub320_sw_cal_files, sub320_sw_asn_3, 'sub320_sw')\n",
    "make_level3_association(sub320_lw_cal_files, sub320_lw_asn_3, 'sub320_lw')\n",
    "\n",
    "make_level3_association(sub640_sw_cal_files, sub640_sw_asn_3, 'sub640_sw')\n",
    "make_level3_association(sub640_lw_cal_files, sub640_lw_asn_3, 'sub640_lw')\n",
    "\n",
    "make_level3_association(full_sw_cal_files, full_sw_asn_3, 'full_sw')\n",
    "make_level3_association(full_lw_cal_files, full_lw_asn_3, 'full_lw')\n",
    "\n",
    "make_level3_association(sub400p_sw_cal_files, sub400p_sw_asn_3, 'sub400p_sw', rule='asn_tso')\n",
    "make_level3_association(sub400p_lw_cal_files, sub400p_lw_asn_3, 'sub400p_lw', rule='asn_tso')\n",
    "\n",
    "make_level3_association(sub64p_sw_cal_files, sub64p_sw_asn_3, 'sub64p_sw', rule='asn_tso')\n",
    "make_level3_association(sub64p_lw_cal_files, sub64p_lw_asn_3, 'sub64p_lw', rule='asn_tso')\n",
    "\n",
    "make_level3_association(substripe256_sw_cal_files, substripe256_sw_asn_3, 'substrip256_sw', rule='asn_tso')\n",
    "make_level3_association(substripe256_lw_cal_files, substripe256_lw_asn_3, 'substripe256_lw', rule='asn_tso')\n",
    "\n",
    "make_level3_association(all_sw_cal_files, all_sw_asn_3, 'all_subarrays_sw')\n",
    "make_level3_association(all_lw_cal_files, all_lw_asn_3, 'all_subarrays_lw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Run calwebb_image3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "association_files_3 = [sub160_sw_asn_3]#, sub160_lw_asn_3, sub320_sw_asn_3, sub320_lw_asn_3,\n",
    "                       #sub640_sw_asn_3, sub640_lw_asn_3, full_sw_asn_3, full_lw_asn_3,\n",
    "                       #all_sw_asn_3, all_lw_asn_3]\n",
    "\n",
    "for asn in association_files_3:\n",
    "    run_calwebb_image3(asn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grism TSO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "association_files_3tso = [sub400p_lw_asn_3, sub400p_sw_asn_3, sub64p_lw_asn_3,\n",
    "                            sub64p_sw_asn_3, substripe256_sw_asn_3, substripe256_lw_asn_3]\n",
    "for asn in association_files_3tso:\n",
    "    run_calwebb_tso3(asn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='goal_2'></a>\n",
    "## Goal 2: Confirm positions of subarrays on detectors are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this goal, we need to confirm that the pixels contained in the subarray files are those expected from the detector. For example, we need to be sure that the B1_SUB640 subarray is composed of pixels x = (1 - 640), y = (1408 - 2048).\n",
    "\n",
    "There are two methods that can be used for this confirmation:\n",
    "\n",
    "1) [Manual examination of images](#manual_examination). In this case the expected pixels are extracted from a raw full frame observation. The bias structure/bad pixels in these extracted pixels are then compared by eye to that in the subarray observation.\n",
    "\n",
    "2) [Compare source locations](#source_locations) in the full frame vs subarray observations. Here, using calibrated or uncalibrated slope images, we use phototils to locate sources in the full frame data. The expected locations of these sources in the subarray are then calculated. These calculated positions are then compared to the measured locations of the sources in the subarray image.\n",
    "\n",
    "Note that CAR-19 does not acquire full frame observations of the A module, so we cannot confirm the subarray location of the stripe subarray in Observation 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal2_output_dir = os.path.join(output_products_dir, 'subarray_position')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='manual_examination'></a>\n",
    "### Manual examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1\n",
    "full = os.path.join(base_dir, 'Mirage_Output/jw01068004001_01101_00001_nrcb1_uncal.fits')\n",
    "subs = [os.path.join(base_dir, 'Mirage_Output/jw01068001001_01101_00001_nrcb1_uncal.fits'),\n",
    "        os.path.join(base_dir, 'Mirage_Output/jw01068002001_01101_00001_nrcb1_uncal.fits'),\n",
    "        os.path.join(base_dir, 'Mirage_Output/jw01068003001_01101_00001_nrcb1_uncal.fits'),\n",
    "       ]\n",
    "for sub in subs:\n",
    "    subarray, cropped, loc_info, comp_file = examination.compare(full_frame_file=full, subarray_file=sub,\n",
    "                                                                 output_dir=output_products_dir)\n",
    "    print('Comparison file saved to: {}'.format(comp_file))\n",
    "    \n",
    "    crop_mean, crop_med, crop_dev = sigma_clipped_stats(cropped, sigma=2, maxiters=5, cenfunc='median')\n",
    "    cmin = crop_med - 3*crop_dev\n",
    "    cmax = crop_med + 3*crop_dev\n",
    "    \n",
    "    sub_mean, sub_med, sub_dev = sigma_clipped_stats(subarray, sigma=2, maxiters=5, cenfunc='median')\n",
    "    smin = crop_med - 3*crop_dev\n",
    "    smax = crop_med + 3*crop_dev\n",
    "    \n",
    "    f, a = plt.subplots(1, 2, figsize = (15, 8))\n",
    "    a[0].imshow(cropped, origin='lower', vmin=cmin, vmax=cmax)\n",
    "    a[1].imshow(subarray, origin='lower', vmin=smin, vmax=smax)\n",
    "    a[0].set_title('Cropped from full frame')\n",
    "    a[1].set_title('Subarray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B5\n",
    "full = os.path.join(base_dir, 'Mirage_Output/jw01068004001_01101_00001_nrcb5_uncal.fits')\n",
    "subs = [os.path.join(base_dir, 'Mirage_Output/jw01068001001_01101_00001_nrcb5_uncal.fits'),\n",
    "        os.path.join(base_dir, 'Mirage_Output/jw01068002001_01101_00001_nrcb5_uncal.fits'),\n",
    "        os.path.join(base_dir, 'Mirage_Output/jw01068003001_01101_00001_nrcb5_uncal.fits'),\n",
    "       ]\n",
    "for sub in subs:\n",
    "    subarray, cropped, loc_info, comp_file = examination.compare(full_frame_file=full, subarray_file=sub,\n",
    "                                                                 output_dir=output_products_dir)\n",
    "    print('Comparison file saved to: {}'.format(comp_file))\n",
    "    \n",
    "    crop_mean, crop_med, crop_dev = sigma_clipped_stats(cropped, sigma=2, maxiters=5, cenfunc='median')\n",
    "    cmin = crop_med - 3*crop_dev\n",
    "    cmax = crop_med + 3*crop_dev\n",
    "    \n",
    "    sub_mean, sub_med, sub_dev = sigma_clipped_stats(subarray, sigma=2, maxiters=5, cenfunc='median')\n",
    "    smin = crop_med - 3*crop_dev\n",
    "    smax = crop_med + 3*crop_dev\n",
    "    \n",
    "    f, a = plt.subplots(1, 2, figsize = (15, 8))\n",
    "    a[0].imshow(cropped, origin='lower', vmin=cmin, vmax=cmax)\n",
    "    a[1].imshow(subarray, origin='lower', vmin=smin, vmax=smax)\n",
    "    a[0].set_title('Cropped from full frame')\n",
    "    a[1].set_title('Subarray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1 - point source subarrays\n",
    "full = os.path.join(base_dir, 'Mirage_Output/jw01068004001_01101_00001_nrcb1_uncal.fits')\n",
    "subs = [os.path.join(base_dir, 'Mirage_Output/jw01068005001_01101_00001_nrcb1_uncal.fits'),\n",
    "        os.path.join(base_dir, 'Mirage_Output/jw01068006001_01101_00001_nrcb1_uncal.fits'),\n",
    "       ]\n",
    "for sub in subs:\n",
    "    subarray, cropped, loc_info, comp_file = examination.compare(full_frame_file=full, subarray_file=sub,\n",
    "                                                                 output_dir=output_products_dir)\n",
    "    print('Comparison file saved to: {}'.format(comp_file))\n",
    "    \n",
    "    crop_mean, crop_med, crop_dev = sigma_clipped_stats(cropped, sigma=2, maxiters=5, cenfunc='median')\n",
    "    cmin = crop_med - 3*crop_dev\n",
    "    cmax = crop_med + 3*crop_dev\n",
    "    \n",
    "    sub_mean, sub_med, sub_dev = sigma_clipped_stats(subarray, sigma=2, maxiters=5, cenfunc='median')\n",
    "    smin = crop_med - 3*crop_dev\n",
    "    smax = crop_med + 3*crop_dev\n",
    "    \n",
    "    f, a = plt.subplots(1, 2, figsize = (15, 8))\n",
    "    a[0].imshow(cropped, origin='lower', vmin=cmin, vmax=cmax)\n",
    "    a[1].imshow(subarray, origin='lower', vmin=smin, vmax=smax)\n",
    "    a[0].set_title('Cropped from full frame')\n",
    "    a[1].set_title('Subarray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B5 - point source subarrays\n",
    "full = os.path.join(base_dir, 'Mirage_Output/jw01068004001_01101_00001_nrcb5_uncal.fits')\n",
    "subs = [os.path.join(base_dir, 'Mirage_Output/jw01068005001_01101_00002_nrcb5_uncal.fits'),\n",
    "        os.path.join(base_dir, 'Mirage_Output/jw01068006001_01101_00002_nrcb5_uncal.fits'),\n",
    "       ]\n",
    "for sub in subs:\n",
    "    subarray, cropped, loc_info, comp_file = examination.compare(full_frame_file=full, subarray_file=sub,\n",
    "                                                                 output_dir=output_products_dir)\n",
    "    print('Comparison file saved to: {}'.format(comp_file))\n",
    "    \n",
    "    crop_mean, crop_med, crop_dev = sigma_clipped_stats(cropped, sigma=2, maxiters=5, cenfunc='median')\n",
    "    cmin = crop_med - 3*crop_dev\n",
    "    cmax = crop_med + 3*crop_dev\n",
    "    \n",
    "    sub_mean, sub_med, sub_dev = sigma_clipped_stats(subarray, sigma=2, maxiters=5, cenfunc='median')\n",
    "    smin = crop_med - 3*crop_dev\n",
    "    smax = crop_med + 3*crop_dev\n",
    "    \n",
    "    f, a = plt.subplots(1, 2, figsize = (15, 8))\n",
    "    a[0].imshow(cropped, origin='lower', vmin=cmin, vmax=cmax)\n",
    "    a[1].imshow(subarray, origin='lower', vmin=smin, vmax=smax)\n",
    "    a[0].set_title('Cropped from full frame')\n",
    "    a[1].set_title('Subarray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='source_locations'></a>\n",
    "### Compare source locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# B1 - SUB160, SUB320, SUB640, FULL\n",
    "full = os.path.join(base_dir, 'Pipeline_Level2/jw01068004001_01101_00002_nrcb1_cal.fits')\n",
    "subs = ['Pipeline_Level2/jw01068001001_01101_00001_nrcb1_cal.fits',\n",
    "        'Pipeline_Level2/jw01068002001_01101_00001_nrcb1_cal.fits',\n",
    "        'Pipeline_Level2/jw01068003001_01101_00001_nrcb1_cal.fits']\n",
    "subs = [os.path.join(base_dir, s) for s in subs]\n",
    "locations.run(full, subs, output_dir=output_products_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# B2 - SUB160, SUB320, SUB640, FULL\n",
    "full = os.path.join(base_dir, 'Pipeline_Level2/jw01068004001_01101_00003_nrcb2_cal.fits')\n",
    "subs = ['Pipeline_Level2/jw01068001001_01101_00001_nrcb2_cal.fits',\n",
    "        'Pipeline_Level2/jw01068002001_01101_00001_nrcb2_cal.fits',\n",
    "        'Pipeline_Level2/jw01068003001_01101_00001_nrcb2_cal.fits']\n",
    "\n",
    "#subs = ['Pipeline_Level2/jw01068002001_01101_00001_nrcb2_cal.fits',\n",
    "#        'Pipeline_Level2/jw01068003001_01101_00001_nrcb2_cal.fits']\n",
    "subs = [os.path.join(base_dir, s) for s in subs]\n",
    "locations.run(full, subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B3 - SUB160, SUB320, SUB640, FULL\n",
    "full = os.path.join(base_dir, 'Pipeline_Level2/jw01068004001_01101_00002_nrcb3_cal.fits')\n",
    "subs = ['Pipeline_Level2/jw01068001001_01101_00001_nrcb3_cal.fits',\n",
    "        'Pipeline_Level2/jw01068002001_01101_00001_nrcb3_cal.fits',\n",
    "        'Pipeline_Level2/jw01068003001_01101_00001_nrcb3_cal.fits']\n",
    "subs = [os.path.join(base_dir, s) for s in subs]\n",
    "locations.run(full, subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B4 - SUB160, SUB320, SUB640, FULL\n",
    "full = os.path.join(base_dir, 'Pipeline_Level2/jw01068004001_01101_00002_nrcb4_cal.fits')\n",
    "subs = ['Pipeline_Level2/jw01068001001_01101_00001_nrcb4_cal.fits',\n",
    "        'Pipeline_Level2/jw01068002001_01101_00001_nrcb4_cal.fits',\n",
    "        'Pipeline_Level2/jw01068003001_01101_00001_nrcb4_cal.fits']\n",
    "subs = [os.path.join(base_dir, s) for s in subs]\n",
    "locations.run(full, subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B5 - SUB160, SUB320, SUB640, FULL\n",
    "full = os.path.join(base_dir, 'Pipeline_Level2/jw01068004001_01101_00001_nrcb5_cal.fits')\n",
    "subs = ['Pipeline_Level2/jw01068001001_01101_00001_nrcb5_cal.fits',\n",
    "        'Pipeline_Level2/jw01068002001_01101_00001_nrcb5_cal.fits',\n",
    "        'Pipeline_Level2/jw01068003001_01101_00001_nrcb5_cal.fits']\n",
    "subs = [os.path.join(base_dir, s) for s in subs]\n",
    "locations.run(full, subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# B1 - SUB64P, SUB600P\n",
    "full = os.path.join(base_dir, 'Pipeline_Level2/jw01068004001_01101_00002_nrcb1_cal.fits')\n",
    "subs = ['Pipeline_Level2/jw01068006001_01101_00001_nrcb1_cal.fits',\n",
    "        'Pipeline_Level2/jw01068005001_01101_00001_nrcb1_cal.fits']\n",
    "subs = [os.path.join(base_dir, s) for s in subs]\n",
    "locations.run(full, subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# B5 - SUB64P, SUB600P\n",
    "full = os.path.join(base_dir, 'Pipeline_Level2/jw01068004001_01101_00001_nrcb5_cal.fits')\n",
    "subs = ['Pipeline_Level2/jw01068006001_01101_00002_nrcb5_cal.fits',\n",
    "        'Pipeline_Level2/jw01068005001_01101_00002_nrcb5_cal.fits']\n",
    "subs = [os.path.join(base_dir, s) for s in subs]\n",
    "locations.run(full, subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='goal_3'></a>\n",
    "## Goal 3: Confirm telescope pointing places the source at the proper location in aperture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this goal, we attempt to confirm that the telescope pointing for each subarray is correct. There are three methods that can be used to do this:\n",
    "\n",
    "1) [Compare source locations to 2MASS catalog](#twomass_comp). Using photutils, locate sources in the input calibrated slope image. Then, starting from a 2MASS catalog, calculate the expected (x, y) locations of sources in the observation. Compare the measured and calculated source positions.\n",
    "\n",
    "2) [Compare target location to expected location](#targ_star_comp). For the point source subarray observations (Observations 5 and 6 in the APT file), the APT target is an actual star with a known RA, Dec. Calculate the expected (x, y) location of this RA, Dec, and compare to the measured star location. This is essentially the same check as is done in the test described above.\n",
    "\n",
    "3) [Check that target RA, Dec in file matches position in APT](#targ_ra_dec_comp). This test simply confirms that the target RA, Dec from the APT file is present in the TARG_RA and TARG_DEC header keywords of the observation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenames = ['Pipeline_Level2/jw01068005001_01101_00001_nrcb1_cal.fits',\n",
    "#             'Pipeline_Level2/jw01068005001_01101_00002_nrcb5_cal.fits',\n",
    "#             'Pipeline_Level2/jw01068006001_01101_00001_nrcb1_cal.fits',\n",
    "#             'Pipeline_Level2/jw01068006001_01101_00002_nrcb5_cal.fits']\n",
    "#filenames = [os.path.join(base_dir, s) for s in filenames]\n",
    "\n",
    "filenames = sorted(glob(os.path.join(base_dir, 'Pipeline_Level2/jw01068*cal.fits')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='twomass_comp'></a>\n",
    "### Compare source locations against expected locations from independent 2MASS catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    med_offset, dev_offset, mean_unc, offsets = \\\n",
    "              pointing.check_pointing_using_2mass_catalog(filename, out_dir=output_products_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='targ_star_comp'></a>\n",
    "### Compare target star location against expected location given its (RA, Dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the target star is only used for the point source subarrays. This check should be redundant after running check_pointing_using_2mass_catalog()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptsrc_filenames = ['Pipeline_Level2/jw01068005001_01101_00001_nrcb1_cal.fits',\n",
    "                   'Pipeline_Level2/jw01068005001_01101_00002_nrcb5_cal.fits',\n",
    "                   'Pipeline_Level2/jw01068006001_01101_00001_nrcb1_cal.fits',\n",
    "                   'Pipeline_Level2/jw01068006001_01101_00002_nrcb5_cal.fits',\n",
    "                   'Pipeline_Level2/jw01068007001_01101_00001-seg001_nrca1_cal.fits',\n",
    "                   'Pipeline_Level2/jw01068007001_01101_00002-seg001_nrca5_cal.fits']\n",
    "ptsrc_filenames = [os.path.join(base_dir, s) for s in ptsrc_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for filename in ptsrc_filenames:\n",
    "    diff = pointing.check_pointing_target_star(filename, out_dir=output_products_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Still need SUBTRIPE256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='targ_ra_dec_comp'></a>\n",
    "### Check that the TARG_RA, TARG_DEC in the file matches that from the APT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lw_files = ['Pipeline_Level2/jw01068005001_01101_00002_nrcb5_cal.fits']\n",
    "#lw_files = [os.path.join(base_dir, lfile) for lfile in lw_files]\n",
    "\n",
    "files = glob(os.path.join(base_dir, 'Pipeline_Level2/jw01068*_cal.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    header0 = fits.getheader(file)\n",
    "    obs = int(header0['OBSERVTN'])\n",
    "    if obs <= 4:\n",
    "        expected_ra = point_ra\n",
    "        expected_dec = point_dec\n",
    "    else:\n",
    "        expected_ra = extended_ra\n",
    "        expected_dec = extended_dec\n",
    "    header_ra, header_dec = pointing.check_targ_ra_dec(header0, expected_ra, expected_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='goal_4'></a>\n",
    "## Goal 4: Charge Accumulation Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the charge accumulation rate in the subarray files is consistent with that in the full frame data. There are three methods that can be used for this:\n",
    "\n",
    "1) [Compare photometry in subarrays vs full frame](#photometry_comparison). Using photutils on calibrated or uncalibrated slope images, locate sources and then do simple aperture photometry on the subarray as well as full frame data. After matching catalogs (and optionally filtering out sources containing any bad pixels), compare the measured signal rates of the sources. \n",
    "\n",
    "2) [Compare level 3 source catalogs](#compare_level3_catalog). Read in the level 3 pipeline-output source catalogs for a product made from full frame observations, as well as a product from subarray observations. Perform catalog matching and compare the photometry results.\n",
    "\n",
    "3) [Examine ratio images with the same pointing](#ratios). In cases where we have a subarray observation at the same pointing as a full frame observation (i.e. the same RA, Dec at the reference location, and the same roll angle), create a ratio image of the calibrated or uncalibrated slope images. Examine the ratio image, and check its median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrate_output_dir = os.path.join(output_products_dir, 'count_rate_comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='photometry_comparison'></a>\n",
    "### Compare photometry results of sources in subarrays and full frame data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, check LW data using calibrated slope images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullframe_file = os.path.join(base_dir, 'Pipeline_level2/jw01068004001_01101_00001_nrcb5_cal.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfiles = sorted(glob(os.path.join(base_dir, 'Pipeline_level2/jw01068001*nrcb5_cal.fits')))\n",
    "\n",
    "for f in subfiles:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_dq and full_dq columns: if True, then there is at least one non-zero value\n",
    "# in the DQ array within the photometry aperture in the subarray or full frame\n",
    "# images, respectively. In some cases this may not matter. But in some cases the\n",
    "# flagged pixel defintely has an effect.\n",
    "\n",
    "# d_phot_p is the percentage difference in the photometry between the subarray\n",
    "# and full frame cases. Eqn is (full frame - subarray) / full frame, so negative\n",
    "# means the source is brighter in the subarray data\n",
    "for subarray_file in subfiles[0:1]:\n",
    "    print('Trying: {}'.format(subarray_file))\n",
    "    phot_tab, clean_phot_tab = count_rates.compare_rate_images(subarray_file, fullframe_file,\n",
    "                                                               output_products_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the resulting photometry table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the table of \"clean\" sources. This table excludes sources where there is a bad pixel flagged in the subarray or full frame DQ arrays at the locations of the sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_phot_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at SW data calibrated slope images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullframe_file = os.path.join(base_dir, 'Pipeline_level2/jw01068004001_01101_00001_nrcb1_cal.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfiles = sorted(glob(os.path.join(base_dir, 'Pipeline_level2/jw01068002*nrcb1_cal.fits')))\n",
    "for subfile in subfiles:\n",
    "    print(subfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subarray_file in subfiles:\n",
    "    print('Trying: {}'.format(subarray_file))\n",
    "    phot_tab, clean_phot_tab = count_rates.compare_rate_images(subarray_file, fullframe_file,\n",
    "                                                               out_dir=output_products_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='compare_level3_catalog'></a>\n",
    "### Compare data in the level 3 output source catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comparison_filename(cat1, cat2):\n",
    "    \"\"\"Construct a filename which will be used to save the table containing\n",
    "    comparitive photometry from two source catalogs\n",
    "    \"\"\"\n",
    "    cat1base = os.path.basename(cat1).replace('.ecsv', '')\n",
    "    cat2base = os.path.basename(cat2).replace('.ecsv', '')\n",
    "    comp_name = 'photometry_comparison_{}_{}.txt'.format(cat1base, cat2base)\n",
    "    return comp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog1 = os.path.join(base_dir, 'Pipeline_level3/sub160_lw_cat.ecsv')\n",
    "catalog2 = os.path.join(base_dir, 'Pipeline_level3/full_lw_cat.ecsv')\n",
    "comparison_output_table = generate_comparison_filename(catalog1, catalog2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_tab = count_rates.compare_level3_catalogs(catalog1, catalog2, comparison_output_table,\n",
    "                                               out_dir=output_products_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_tab['delta_flux_perc'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog1 = os.path.join(base_dir, 'Pipeline_level3/sub160_sw_cat.ecsv')\n",
    "catalog2 = os.path.join(base_dir, 'Pipeline_level3/full_sw_cat.ecsv')\n",
    "comparison_output_table = generate_comparison_filename(catalog1, catalog2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_tab = count_rates.compare_level3_catalogs(catalog1, catalog2, comparison_output_table,\n",
    "                                               out_dir=output_products_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_tab['delta_flux_perc'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ratios'></a>\n",
    "### Examine ratio images of images with the same pointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1 through B5 - grab only the first exposure\n",
    "sub160_pointing1 = sorted(glob(os.path.join(base_dir, 'Mirage_Output/jw01068001001_01101_00001*uncal.fits')))\n",
    "sub320_pointing1 = sorted(glob(os.path.join(base_dir, 'Mirage_Output/jw01068002001_01101_00001*uncal.fits')))\n",
    "sub640_pointing1 = sorted(glob(os.path.join(base_dir, 'Mirage_Output/jw01068003001_01101_00001*uncal.fits')))\n",
    "full_pointing1 = sorted(glob(os.path.join(base_dir, 'Mirage_Output/jw01068004001_01101_00001*uncal.fits')))\n",
    "full_b1_b5_only = [full_pointing1[0], full_pointing1[-1]]\n",
    "\n",
    "# B1 and B5 only - grab only the second exposure (the first exposure is the TA)\n",
    "sub400p_pointing2 = sorted(glob(os.path.join(base_dir, 'Mirage_Output/jw01068005001_01101_00002*uncal.fits')))\n",
    "sub64p_pointing2 = sorted(glob(os.path.join(base_dir, 'Mirage_Output/jw01068006001_01101_00002*uncal.fits')))\n",
    "\n",
    "# I don't think we can use the TSO observation here because of the small shift in y that is\n",
    "# used to get the target to the reference location\n",
    "#sub256_pointing1 = sorted(glob(os.path.join(base_dir, 'Mirage_Output/jw01068007001_01101_00002*uncal.fits')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ratios(file1, file2):\n",
    "    with fits.open(file1) as f:\n",
    "        detector = f[0].header['DETECTOR']\n",
    "        aperture1 = f[0].header['SUBARRAY']\n",
    "    with fits.open(file2) as f:\n",
    "        aperture2 = f[0].header['SUBARRAY']\n",
    "\n",
    "    ratio_image, ratio_med = count_rates.ratio_images(file1, file2, out_dir=countrate_output_dir)\n",
    "    print('Median of ratio image: {}'.format(ratio_med))\n",
    "    f, a = plt.subplots(figsize=(10,10))\n",
    "    a.imshow(ratio_image, origin='lower', vmin=0.2, vmax=20)\n",
    "    a.set_title('{} / {}, {}'.format(aperture1, aperture2, detector))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be looping over detectors\n",
    "for file_160, file_full in zip(sub160_pointing1, full_pointing1):\n",
    "    calculate_ratios(file_160, file_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be looping over detectors\n",
    "for file_320, file_full in zip(sub320_pointing1, full_pointing1):\n",
    "    calculate_ratios(file_320, file_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be looping over detectors.\n",
    "for file_640, file_full in zip(sub640_pointing1, full_pointing1):\n",
    "    calculate_ratios(file_640, file_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be looping over detectors. In this case we want only the B1\n",
    "# and B5 files from the full frame observation\n",
    "for file_400p, file_full in zip(sub400p_pointing2, full_pointing1):\n",
    "    calculate_ratios(file_400p, file_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be looping over detectors. In this case we want only the B1\n",
    "# and B5 files from the full frame observation\n",
    "for file_64p, file_full in zip(sub64p_pointing2, full_pointing1):\n",
    "    calculate_ratios(file_64p, file_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='goal_5'></a>\n",
    "## Goal 5: Identify and characterize latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using _cal.fits files:\n",
    "\n",
    "0. Mario has HST/WFC3 scripts that are a good place to start\n",
    "1. Locate and do aperture photometry on sources in exposure 1\n",
    "2. Locate and do aperture photometry on sources in exposure 2\n",
    "3. In exposure 2, do aperture photometry on locations from exposure 1, excluding locations where there is also a source in exposure 2.\n",
    "4. Create plot of \"empty\" location photometry vs time since dither?\n",
    "5. Repeat for subsequent exposures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob('Pipeline_Level1/jw01068001001*nrcb5_rateints.fits'))\n",
    "files = [os.path.join(base_dir, f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency.check(files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
